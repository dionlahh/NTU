{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries / Functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "#import pytrends\n",
    "#from pytrends.request import TrendReq\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import *\n",
    "startTime = time.time()\n",
    "#pytrend = TrendReq(hl='en-GB', tz=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'movies/476000-480000.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2116ca7eeda0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m   \u001b[0mmovieData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmovieData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmovieData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adult'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m#Drop adult films\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m   \u001b[0mmovieData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'movies/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m   \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m   \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movies/476000-480000.csv'"
     ]
    }
   ],
   "source": [
    "x1 = 476000\n",
    "x2 = 480000\n",
    "count = 0\n",
    "\n",
    "while count<8:\n",
    "\n",
    "  movielist=[]\n",
    "  for i in range(x1,x2):\n",
    "        url=\"https://api.themoviedb.org/3/movie/\"+str(i)+\"?api_key=4568df78fb309238e68974a24013b626\"\n",
    "        try:\n",
    "            JSONContent = urlopen(url)\n",
    "        except:\n",
    "            #If there's no such movie, then go to the next loop\n",
    "            continue\n",
    "        detaildata = json.loads(JSONContent.read())\n",
    "        movielist.append(detaildata)  #Add the details to the list\n",
    "\n",
    "     \n",
    "  movieData=pd.json_normalize(movielist)  #Convert raw JSON data in list to Dataframe\n",
    "\n",
    "  \n",
    "  movieData = movieData[movieData['original_language'] == 'en'] #Drop rows that do not have English as og language\n",
    "\n",
    "  #Drop rows that have no tagline/imdb_id\n",
    "  movieData=movieData[movieData['tagline'].notnull()]\n",
    "  movieData=movieData[movieData['imdb_id'].notnull()]\n",
    " \n",
    "  movieData=movieData[movieData['adult']!=True]  #Drop adult films\n",
    "  movieData.to_csv('movies/' + str(x1) + '-' + str(x2) + '.csv')\n",
    "  x1 = x1 + 2000\n",
    "  x2 = x2 + 2000\n",
    "  count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the Dataframes into 1\n",
    "titleData8=pd.read_csv('movies/476000-480000.csv')\n",
    "titleData7=pd.read_csv('movies/480000-484000.csv')\n",
    "titleData1=pd.read_csv('movies/484000-486000.csv')\n",
    "titleData2=pd.read_csv('movies/486000-488000.csv')\n",
    "titleData3=pd.read_csv('movies/488000-490000.csv')\n",
    "titleData4=pd.read_csv('movies/490000-492000.csv')\n",
    "titleData5=pd.read_csv('movies/492000-494013.csv')\n",
    "titleData6=pd.read_csv('movies/494013-496000.csv')\n",
    "\n",
    "comb=[titleData8,titleData7,titleData1,titleData2,titleData3,titleData4,titleData5,titleData6]\n",
    "final=pd.concat(comb)\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscarData=pd.read_csv(\"oscaraward.csv\") #Drop oscar nomination to individual that did not work on any films\n",
    "\n",
    "oscarData=oscarData[oscarData['film'].notnull()]#Drop movies older than 2010\n",
    "\n",
    "oscarData=oscarData[oscarData['year_film']>=2010]#Create a new Dataframe with film's year of release and name\n",
    "\n",
    "cleanOscarData=pd.DataFrame(oscarData[['year_film','film']])#Count how many times film appeared in the Dataframe and append it to a new row called freq\n",
    "\n",
    "cleanOscarData['freq']=cleanOscarData.groupby('film').transform('count') #Delete all duplicates rows\n",
    "\n",
    "cleanOscarData.drop_duplicates('film',keep='first',inplace=True)\n",
    "\n",
    "cleanOscarData.to_csv(\"cleanoscar.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielist=[]\n",
    "for i in range(len(cleanOscarData['film'])):\n",
    "    movieName=cleanOscarData['film'].values[i] #Ignore weird ascii characters like Ã,©\n",
    "    \n",
    "    movieName = movieName.encode('ascii', 'ignore').decode('ascii') #TMDB uses \"+\" instead of space for separators, so convert all spaces to \"+\"\"\n",
    "    \n",
    "    movieName=movieName.replace(\" \",\"+\") #Get year of release\n",
    "    \n",
    "    oscarYear=cleanOscarData['year_film'].values[i]\n",
    "   \n",
    "    url = \"https://api.themoviedb.org/3/search/movie?api_key=4568df78fb309238e68974a24013b626&query=\"+movieName  #Query for movie id\n",
    "    JSONContent = urlopen(url)\n",
    "    data = json.loads(JSONContent.read())\n",
    "    \n",
    "    #Enter the \"results\" array in data\n",
    "    for i in range(len(data['results'])):\n",
    "        results=data['results'][i]\n",
    "        date=results['release_date']\n",
    "        date=date.split(\"-\")[0]\n",
    "        #Due to number of movies with similar name,\n",
    "        #Compare year of release to Oscar nomination year\n",
    "        #Limitation: If there's another movie with the similar name and same year of release, it might grab the wrong movie\n",
    "        if (str(oscarYear) == date.strip()):\n",
    "            movieID=results['id']\n",
    "            break\n",
    "\n",
    "    #Query for movie details\n",
    "    url=\"https://api.themoviedb.org/3/movie/\"+str(movieID)+\"?api_key=4568df78fb309238e68974a24013b626\"\n",
    "    try:\n",
    "        JSONContent = urlopen(url)\n",
    "    except:\n",
    "        pass\n",
    "    detaildata = json.loads(JSONContent.read())\n",
    "    movielist.append(detaildata)\n",
    "   \n",
    "    movieData=pd.json_normalize(movielist) \n",
    "    \n",
    "#Export Dataframe\n",
    "movieData.to_csv('omoviedb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanOscarData=pd.read_csv(\"cleanoscar.csv\")\n",
    "movieData = pd.read_csv(\"omoviedb.csv\")\n",
    "#Get the release date of the movie\n",
    "#Match film name is cleanOscarData to film name in movieData\n",
    "cleanOscarData['release_date'] = cleanOscarData.film.map(movieData.set_index('title')['release_date'])\n",
    "#Remove rows that do no have a release date\n",
    "cleanOscarData=cleanOscarData[cleanOscarData['release_date'].notnull()]\n",
    "cleanOscarData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect data from Google Trend\n",
    "dataset = []\n",
    "for x in range(400,458):\n",
    "    #Convert date string to Datetime object\n",
    "     date= datetime.strptime(cleanOscarData['release_date'][x], '%Y-%m-%d').date()\n",
    "    #Add a month to the Datetime\n",
    "     date2 = date+relativedelta(months=+1)\n",
    "     timeframeDate = str(date) + \" \"+str(date2)\n",
    "    #Keyword = Film name\n",
    "     keywords = [cleanOscarData['film'][x]]\n",
    "     pytrend.build_payload(\n",
    "     kw_list=keywords,\n",
    "     cat=0,\n",
    "    #Timeframe = a month after movie release\n",
    "     timeframe=timeframeDate,\n",
    "    #Location = US\n",
    "     geo='US')\n",
    "     data = pytrend.interest_over_time()\n",
    "     if not data.empty:\n",
    "          data = data.drop(labels=['isPartial'],axis='columns')\n",
    "          dataset.append(data)\n",
    "\n",
    "result = pd.concat(dataset, axis=1)\n",
    "\n",
    "executionTime = (time.time() - startTime)\n",
    "print('Execution time in sec.: ' + str(executionTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Google Data\n",
    "result.to_csv(\"googleTrends/457.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('googleTrends/457.csv')\n",
    "#Set header as \"date\"\n",
    "test.set_index(test['date'],inplace=True)\n",
    "test=test.transpose()\n",
    "#Remove duplicate header\n",
    "test=test[1:]\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
